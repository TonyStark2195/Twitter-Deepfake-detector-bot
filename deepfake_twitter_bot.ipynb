{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from kernel_utils import VideoReader, FaceExtractor, confident_strategy, predict_on_video_set\n",
    "from training.zoo.classifiers import DeepFakeClassifier\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "import moviepy.editor as mp\n",
    "import re\n",
    "import logging\n",
    "from config import create_api\n",
    "import tweepy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading state dict ./weights\\final_111_DeepFakeClassifier_tf_efficientnet_b7_ns_0_36\n"
     ]
    }
   ],
   "source": [
    "weights_folder = './weights'\n",
    "models = []\n",
    "model_paths = [os.path.join(weights_folder, model) for model in os.listdir(weights_folder)]\n",
    "for path in model_paths:\n",
    "    model = DeepFakeClassifier(encoder=\"tf_efficientnet_b7_ns\").to(\"cuda\")\n",
    "    print(\"loading state dict {}\".format(path))\n",
    "    checkpoint = torch.load(path, map_location=\"cpu\")\n",
    "    state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
    "    model.load_state_dict({re.sub(\"^module.\", \"\", k): v for k, v in state_dict.items()}, strict=True)\n",
    "    model.eval()\n",
    "    del checkpoint\n",
    "    models.append(model.half())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_deepfake_module(tweet):\n",
    "    video_link_list = tweet.extended_entities['media'][0]['video_info']['variants']\n",
    "\n",
    "    top_res = []\n",
    "    for vll in video_link_list:\n",
    "        if 'bitrate' in vll:\n",
    "            top_res.append([vll['bitrate'], vll['url']])\n",
    "\n",
    "    best_vid_link = sorted(top_res, reverse=True)[0][1]\n",
    "    \n",
    "    print(best_vid_link)\n",
    "    \n",
    "    urllib.request.urlretrieve(best_vid_link, './tweet_videos/tweet_deepfake_detect.mp4') \n",
    "    \n",
    "    clip = mp.VideoFileClip(\"./tweet_videos/tweet_deepfake_detect.mp4\")\n",
    "    clip_resized = clip.resize(height=1080) # make the height 360px ( According to moviePy documenation The width is then computed so that the width/height ratio is conserved.)\n",
    "    clip_resized.write_videofile(\"./tweet_videos/tweet_deepfake_detect_1080p.mp4\")\n",
    "    \n",
    "    os.remove('./tweet_videos/tweet_deepfake_detect.mp4')\n",
    "    \n",
    "    frames_per_video = 32\n",
    "    video_reader = VideoReader()\n",
    "    video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n",
    "    face_extractor = FaceExtractor(video_read_fn)\n",
    "    input_size = 380\n",
    "    strategy = confident_strategy\n",
    "    stime = time.time()\n",
    "\n",
    "    video_folder = './tweet_videos'\n",
    "    test_videos = os.listdir(video_folder)\n",
    "    print(\"Predicting {} videos\".format(len(test_videos)))\n",
    "    predictions = predict_on_video_set(face_extractor=face_extractor, input_size=input_size, models=models,\n",
    "                                       strategy=strategy, frames_per_video=frames_per_video, videos=test_videos,\n",
    "                                       num_workers=6, test_dir=video_folder)\n",
    "    \n",
    "    \n",
    "    os.remove('./tweet_videos/tweet_deepfake_detect_1080p.mp4')\n",
    "    \n",
    "    return \"AI response: Fake\" if round(predictions[0]) else \"AI response: Not a Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def check_mentions(api, since_id):\n",
    "    logger.info(\"Retrieving mentions\")\n",
    "    new_since_id = since_id\n",
    "    for tweet in tweepy.Cursor(api.mentions_timeline,\n",
    "        since_id=since_id).items():\n",
    "        new_since_id = max(tweet.id, new_since_id)\n",
    "        \n",
    "        if tweet.in_reply_to_status_id is not None:\n",
    "            continue\n",
    "            \n",
    "        if 'extended_entities' not in tweet._json:\n",
    "            continue\n",
    "            \n",
    "        if any(keyword in tweet.text.lower() for keyword in ['detect', 'ai']):\n",
    "            logger.info(f\"Using AI for {tweet.user.name}, to detect deepfake\")\n",
    "            \n",
    "            print(tweet.text.lower())\n",
    "\n",
    "            output = detect_deepfake_module(tweet)\n",
    "            \n",
    "            print(\"Also sending to Toloka for analysis and feedback!\")\n",
    "            \n",
    "            api.update_status(\n",
    "                status=output,\n",
    "                in_reply_to_status_id=tweet.id,\n",
    "            )\n",
    "\n",
    "        elif any(keyword in tweet.text.lower() for keyword in ['detect', 'human']):\n",
    "            logger.info(f\"Using Human experts for {tweet.user.name}, to detect deepfake\")\n",
    "            \n",
    "            print(tweet.text.lower())\n",
    "\n",
    "            api.update_status(\n",
    "                status=\"Forwarded to digital forensics team, Will generate report and respond shortly!\",\n",
    "                in_reply_to_status_id=tweet.id,\n",
    "            )\n",
    "            \n",
    "    return new_since_id\n",
    "\n",
    "def main():\n",
    "    api = create_api()\n",
    "    # doing this to avoid collecting older tweets and responding to it\n",
    "    for tweet in tweepy.Cursor(api.mentions_timeline,since_id=1).items():\n",
    "        print(tweet.id)\n",
    "        break\n",
    "    since_id = tweet.id\n",
    "#     since_id = 1\n",
    "    while True:\n",
    "        since_id = check_mentions(api, since_id)\n",
    "        logger.info(\"Waiting...\")\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:API created\n",
      "INFO:root:Retrieving mentions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1469119815843397633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Using AI for Aswin Shriram (academic), to detect deepfake\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@aswinacademic detect deepfake in this video using ai https://t.co/qroiwobpz0\n",
      "https://video.twimg.com/ext_tw_video/1469137162390016000/pu/vid/720x1280/rxb98HDJ6hZd4v5i.mp4?tag=12\n",
      "Moviepy - Building video ./tweet_videos/tweet_deepfake_detect_1080p.mp4.\n",
      "MoviePy - Writing audio in tweet_deepfake_detect_1080pTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./tweet_videos/tweet_deepfake_detect_1080p.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t: 100%|███████████████████████████████████████████████████████████████████| 299/299 [00:06<00:00, 48.20it/s, now=None]WARNING:py.warnings:C:\\Users\\aswin\\AppData\\Roaming\\Python\\Python37\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:130: UserWarning: Warning: in file ./tweet_videos/tweet_deepfake_detect.mp4, 2764800 bytes wanted but 0 bytes read,at frame 298/299, at time 10.02/10.03 sec. Using the last valid frame instead.\n",
      "  UserWarning)\n",
      "\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./tweet_videos/tweet_deepfake_detect_1080p.mp4\n",
      "Predicting 1 videos\n",
      "Also sending to Toloka for analysis and feedback!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n",
      "INFO:root:Retrieving mentions\n",
      "INFO:root:Waiting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-1974bcd7f14a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0msince_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_mentions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msince_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Waiting...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
